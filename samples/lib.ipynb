{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "import mrcnn\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.model import MaskRCNN\n",
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "import colorsys\n",
    "import argparse\n",
    "import imutils\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from keras.models import load_model\n",
    "%matplotlib inline\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myMaskRCNNConfig(Config):\n",
    "    # give the configuration a recognizable name\n",
    "    NAME = \"MaskRCNN_config\"\n",
    " \n",
    "    # set the number of GPUs to use along with the number of images\n",
    "    # per GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    " \n",
    "    # number of classes (we would normally add +1 for the background)\n",
    "     # roofs + BG\n",
    "    NUM_CLASSES = 1+1\n",
    "   \n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 131\n",
    "    \n",
    "    # Learning rate\n",
    "    LEARNING_RATE=0.006\n",
    "    \n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    \n",
    "    # setting Max ground truth instances\n",
    "    MAX_GT_INSTANCES=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = myMaskRCNNConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.006\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               10\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           MaskRCNN_config\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                131\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class roofDataset(Dataset):\n",
    "    # load the dataset definitions\n",
    "    def load_dataset(self, dataset_dir, is_train=True):\n",
    "        \n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"dataset\", 1, \"roof\")\n",
    "        \n",
    "        # define data locations for images and annotations\n",
    "        images_dir = dataset_dir + '\\\\images\\\\'\n",
    "        annotations_dir = dataset_dir + '\\\\annots\\\\'\n",
    "        \n",
    "        # Iterate through all files in the folder to \n",
    "        #add class, images and annotaions\n",
    "        for filename in listdir(images_dir):\n",
    "            \n",
    "            # extract image id\n",
    "            image_id = filename[:-4]\n",
    "            \n",
    "            # skip bad images\n",
    "            if image_id in ['00090']:\n",
    "                continue\n",
    "            # skip all images after 150 if we are building the train set\n",
    "            if is_train and int(image_id) >= 150:\n",
    "                continue\n",
    "            # skip all images before 150 if we are building the test/val set\n",
    "            if not is_train and int(image_id) < 150:\n",
    "                continue\n",
    "            \n",
    "            # setting image file\n",
    "            img_path = images_dir + filename\n",
    "            \n",
    "            # setting annotations file\n",
    "            ann_path = annotations_dir + image_id + '.xml'\n",
    "            \n",
    "            # adding images and annotations to dataset\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "# extract bounding boxes from an annotation file\n",
    "    def extract_boxes(self, filename):\n",
    "        \n",
    "        # load and parse the file\n",
    "        tree = ElementTree.parse(filename)\n",
    "        # get the root of the document\n",
    "        root = tree.getroot()\n",
    "        # extract each bounding box\n",
    "        boxes = list()\n",
    "        for box in root.findall('.//bndbox'):\n",
    "            xmin = int(box.find('xmin').text)\n",
    "            ymin = int(box.find('ymin').text)\n",
    "            xmax = int(box.find('xmax').text)\n",
    "            ymax = int(box.find('ymax').text)\n",
    "            coors = [xmin, ymin, xmax, ymax]\n",
    "            boxes.append(coors)\n",
    "        \n",
    "        # extract image dimensions\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        return boxes, width, height\n",
    "# load the masks for an image\n",
    "    \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "     \"\"\"\n",
    "    def load_mask(self, image_id):\n",
    "        # get details of image\n",
    "        info = self.image_info[image_id]\n",
    "        \n",
    "        # define anntation  file location\n",
    "        path = info['annotation']\n",
    "        \n",
    "        # load XML\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "       \n",
    "        # create one array for all masks, each on a different channel\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        \n",
    "        # create masks\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "            class_ids.append(self.class_names.index('kangaroo'))\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    "# load an image reference\n",
    "     \"\"\"Return the path of the image.\"\"\"\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        print(info)\n",
    "        return info['path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train set\n",
    "train_set = roofDataset()\n",
    "train_set.load_dataset(‘..\\\\roof\\\\roof-master\\\\roof-master’, is_train=True)\n",
    "train_set.prepare()\n",
    "print(‘Train: %d’ % len(train_set.image_ids))\n",
    "# prepare test/val set\n",
    "test_set = roofDataset()\n",
    "test_set.load_dataset(‘..\\\\roof\\\\roof-master\\\\roof-master’, is_train=False)\n",
    "test_set.prepare()\n",
    "print(‘Test: %d’ % len(test_set.image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Mask R-CNN model for “training” using the Config instance that we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Mask R-CNN model...\")\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the pre-trained weights for the Mask R-CNN from COCO data set excluding the last few layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the weights for COCO\n",
    "model.load_weights('.\\\\Mask_RCNN\\\\mask_rcnn_coco.h5', \n",
    "                   by_name=True, \n",
    "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the heads with higher learning rate to speed up the learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train heads with higher lr to speedup the learning\n",
    "model.train(train_set, test_set, learning_rate=2*config.LEARNING_RATE, epochs=5, layers=’heads’)\n",
    "history = model.keras_model.history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained weights for custom data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '..\\\\Kangaroo\\\\kangaroo-master\\\\kangaroo-master\\\\mask_rcnn_'  + '.' + str(time.time()) + '.h5'\n",
    "model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting objects in the image with masks and bounding box from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "#Loading the model in the inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir='./')\n",
    "# loading the trained weights o the custom dataset\n",
    "model.load_weights(model_path, by_name=True)\n",
    "img = load_img(\"..\\\\roof\\\\roof-master\\\\roof-master\\\\images\\\\00042.jpg\")\n",
    "img = img_to_array(img)\n",
    "# detecting objects in the image\n",
    "result= model.detect([img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 20\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =    modellib.load_image_gt(test_set, config, image_id, use_mini_mask=False)\n",
    "info = test_set.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                       test_set.image_reference(image_id)))\n",
    "# Run object detection\n",
    "results = model.detect([image], verbose=1)\n",
    "# Display results\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            test_set.class_names, r['scores'], \n",
    "                            title=\"Predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
